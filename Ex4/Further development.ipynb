{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df427fa3",
   "metadata": {},
   "source": [
    "# Vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af539fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vosk in /Users/anon/opt/anaconda3/lib/python3.8/site-packages (0.3.32)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/anon/opt/anaconda3/lib/python3.8/site-packages (from vosk) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/anon/opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.0->vosk) (2.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aac76a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:CompileLooped():nnet-compile-looped.cc:345) Spent 0.041718 seconds in looped compilation.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:281) Loading HCL and G from vosk-model-small-en-us-0.15/graph/HCLr.fst vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:302) Loading winfo vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    }
   ],
   "source": [
    "import vosk\n",
    "from vosk import Model, KaldiRecognizer\n",
    "model = Model('vosk-model-small-en-us-0.15')\n",
    "recognizer = KaldiRecognizer(model,16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20f60f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin = \"where is the check in desk\"\n",
    "parents = \"i have lost my parents\"\n",
    "suitcase = \"please i have lost my suitcase\"\n",
    "what_time = \"what time is my plane\"\n",
    "where = \"where are the restaurants and shops\"\n",
    "\n",
    "en = [checkin, parents, suitcase, what_time, where]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ab17ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import numpy as np\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "from jiwer import wer\n",
    "import json\n",
    "import wave\n",
    "\n",
    "def translate(wf):\n",
    "    transcription = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            # Convert json output to dict\n",
    "            result_dict = json.loads(recognizer.Result())\n",
    "            # Extract text values and append them to transcription list\n",
    "            transcription.append(result_dict.get(\"text\", \"\"))\n",
    "\n",
    "    # Get final bits of audio and flush the pipeline\n",
    "    final_result = json.loads(recognizer.FinalResult())\n",
    "    transcription.append(final_result.get(\"text\", \"\"))\n",
    "\n",
    "    # merge or join all list elements to one big string\n",
    "    transcription_text = ' '.join(transcription)\n",
    "    return transcription_text\n",
    "\n",
    "def fileRead(directory):\n",
    "    table = PrettyTable([\"File\",\"WER\"])\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            audio_file = filepath\n",
    "            wf = wave.open(audio_file,'rb')\n",
    "            res = translate(wf)\n",
    "            transcription = filepath.strip(\"EN/\")\n",
    "            print(transcription)\n",
    "            print(res)\n",
    "            if transcription.startswith(\"checkin\"):\n",
    "                tablewer = wer(en[0],res)\n",
    "            elif transcription.startswith(\"parents\"):\n",
    "                tablewer = wer(en[1],res)\n",
    "            elif transcription.startswith(\"suitcase\"):\n",
    "                tablewer = wer(en[2],res)\n",
    "            elif transcription.startswith(\"what_time\"):\n",
    "                tablewer = wer(en[3],res)\n",
    "            elif transcription.startswith(\"where\"):\n",
    "                tablewer = wer(en[4],res)\n",
    "        table.add_row([transcription, tablewer*100])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e815602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where.wav\n",
      "where are the restaurants and shops\n",
      "parents.wav\n",
      "i lost my parents\n",
      "suitcase.wav\n",
      "please have lost my suitcase\n",
      "checkin.wav\n",
      "where is the check in desk\n",
      "what_time.wav\n",
      "what time is my plane\n",
      "+---------------+--------------------+\n",
      "|      File     |        WER         |\n",
      "+---------------+--------------------+\n",
      "|   where.wav   |        0.0         |\n",
      "|  parents.wav  |        20.0        |\n",
      "|  suitcase.wav | 16.666666666666664 |\n",
      "|  checkin.wav  |        0.0         |\n",
      "| what_time.wav |        0.0         |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "directory = 'EN/'\n",
    "fileRead(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2691f2",
   "metadata": {},
   "source": [
    "Reference: https://towardsdatascience.com/transcribe-large-audio-files-offline-with-vosk-a77ee8f7aa28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6cc4a",
   "metadata": {},
   "source": [
    "# Google Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73a9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /Users/anon/opt/anaconda3/lib/python3.8/site-packages (3.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fd1320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import numpy as np\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "from jiwer import wer\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "\n",
    "def fileRead(directory):\n",
    "    table = PrettyTable([\"File\",\"WER\"])\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            AUDIO_FILE = filepath\n",
    "            r = sr.Recognizer()\n",
    "            with sr.AudioFile(AUDIO_FILE) as source:\n",
    "                audio = r.record(source)  # read the entire audio file\n",
    "            res = r.recognize_google(audio)\n",
    "            transcription = filepath.strip(\"EN/\")\n",
    "            print(transcription)\n",
    "            print(res)\n",
    "            if transcription.startswith(\"checkin\"):\n",
    "                tablewer = wer(en[0],res)\n",
    "            elif transcription.startswith(\"parents\"):\n",
    "                tablewer = wer(en[1],res)\n",
    "            elif transcription.startswith(\"suitcase\"):\n",
    "                tablewer = wer(en[2],res)\n",
    "            elif transcription.startswith(\"what_time\"):\n",
    "                tablewer = wer(en[3],res)\n",
    "            elif transcription.startswith(\"where\"):\n",
    "                tablewer = wer(en[4],res)\n",
    "        table.add_row([transcription, tablewer*100])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6dcca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where.wav\n",
      "where are the restaurants and shops\n",
      "parents.wav\n",
      "I have lost my parents\n",
      "suitcase.wav\n",
      "please I've lost my suitcase\n",
      "checkin.wav\n",
      "where is the check-in desk\n",
      "what_time.wav\n",
      "what time is my playing\n",
      "+---------------+-------------------+\n",
      "|      File     |        WER        |\n",
      "+---------------+-------------------+\n",
      "|   where.wav   |        0.0        |\n",
      "|  parents.wav  |        20.0       |\n",
      "|  suitcase.wav | 33.33333333333333 |\n",
      "|  checkin.wav  | 33.33333333333333 |\n",
      "| what_time.wav |        20.0       |\n",
      "+---------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "directory = 'EN'\n",
    "fileRead(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb14f0",
   "metadata": {},
   "source": [
    "Reference: https://github.com/Uberi/speech_recognition/blob/master/examples/audio_transcribe.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
